{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468ee24a-72a3-4c29-9338-c55aeb75e6fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9420/71394778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import os #PythonBib für Datei-Input/-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad9399a-7798-41aa-a799-a73fac3914ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9420/2195001292.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda:0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('This Conputation is running on {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04f1b6-6e52-4e84-80df-88dc7d01053f",
   "metadata": {},
   "source": [
    "Bilder importieren\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac06b2-972d-4936-9960-605d5888d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.Resize(197),\n",
    "                                 transforms.CenterCrop(197),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5,), (0.5,))\n",
    "                                ])\n",
    "\n",
    "#Batch_size definieren, um Variable wieder zu verwenden und spätere Fehler zu vermeiden\n",
    "batchSize = 7\n",
    "\n",
    "#Bilder aus dem verzeichnis in einen Tensor schreiben\n",
    "true_images_list = []\n",
    "for f in listdir('C:/Users/meldr/PythonProjects/Aufgabe04/Bilder/cropped/'):\n",
    "    img = Image.open(\"C:/Users/meldr/PythonProjects/Aufgabe04/Bilder/cropped/\" + f) # f ist gleich der Dateiname\n",
    "    img_tensor = transforms(img) #(3,100,100)\n",
    "    true_images_list.append(img_tensor)\n",
    "train_data = torch.stack(true_images_list) #Liste mit Image-Tensoren\n",
    "\n",
    "#DataLoader für echte Bilder\n",
    "trueloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=True, num_workers=1, pin_memory=True) #pin_memory=True -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df3ffe-ca30-4393-b3e5-86960bdc8e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__() #Superkonstruktor für das NN\n",
    "        #decoder\n",
    "        #batch_size = 4, size = 2500 (50x50 Pixel)\n",
    "        self.generate = nn.Sequential(\n",
    "            nn.ConvTranspose2d(3, 64, 5, stride=2, padding=2), \n",
    "            nn.ReLU(), #Relu-Aktivierungsfunktion\n",
    "            nn.ConvTranspose2d(64, 128, 5, stride=2, padding=2), \n",
    "            nn.ReLU(), #Relu-Aktivierungsfunktion\n",
    "            nn.ConvTranspose2d(128, 3, 5, stride=1, padding=2),\n",
    "            #Sigmoid-Aktivierungsfunktion, wenn unsere Werte zwischen 0 und 1 sind\n",
    "            #Tanh-Aktivierungsfunktion, wenn unsere Werte zwischen -1 und 1 sind\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(f'Input Generator:{x.shape}')\n",
    "        generated = self.generate(x)\n",
    "        #print(f'Output Generator:{generated.shape}')\n",
    "        return generated\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e126f-5106-4a00-ab16-82e3621d1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__() #Superkonstruktor für das NN\n",
    "        \n",
    "        #batch_size = 4, size = 2500 (50x50 Pixel)\n",
    "        self.discriminate = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 5, stride=2, padding=2), # 2500=(1+2500-5+2*2)/1\n",
    "            nn.ReLU(), #Relu-Aktivierungsfunktion\n",
    "            nn.Conv2d(128, 64, 5, stride=2, padding=2), # 625=(1+2500-5+2*2)/2\n",
    "            nn.ReLU(), #Relu-Aktivierungsfunktion\n",
    "            nn.Conv2d(64, 32, 5, stride=2, padding=2), # 125=(1+625-5+2*2)/2\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(f'Input Discriminator:{x.shape}')\n",
    "        discriminated = self.discriminate(x)\n",
    "        #print(f'Output Discriminator:{discriminated.shape}')\n",
    "        return discriminated\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0a2f2-8d74-4875-8aa4-68200cb1e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "discr_optimizer = optim.Adam(discriminator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d870446-5be0-4bfb-b379-d5898ea51945",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ccacae91be8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m#G.1 Daten mit der Random-Noise generieren\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mfake_generated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m#G.2 Fehler mit der fake_generated und den Target 11111... berechnen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mloss_gen_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_generated\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m197\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m197\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-39e04b9bf4a8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#print(f'Input Generator:{x.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mgenerated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m#print(f'Output Generator:{generated.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    914\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m         return F.conv_transpose2d(\n\u001b[0m\u001b[0;32m    917\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "#Definition der Target-Werte, um den Loss zu berechnen\n",
    "true_target = torch.ones(batchSize, 256, 197, 197, dtype=torch.float).to(device)\n",
    "#Die echten Inputs sollen auf den Wert 1 trainiert werden\n",
    "#torch.ones: Gibt einen Tensor zurück, der mit dem Skalarwert 1 gefüllt ist  \n",
    "#und dessen Form durch das variable Argument size definiert ist. \n",
    "#Bspw. torch.ones(5) -> tensor([ 1.,  1.,  1.,  1.,  1.])\n",
    "\n",
    "false_target = torch.zeros(batchSize,125,3,3, dtype=torch.long).to(device)\n",
    "#Die falschen Inputs sollen auf en Wert 0 trainiert werden\n",
    "#torch.zeros: Gibt einen Tensor zurück, der mit dem Skalarwert 0 gefüllt ist  \n",
    "#und dessen Form durch das variable Argument size definiert ist. \n",
    "#Bspw. torch.zeros(5) -> tensor([ 0.,  0.,  0.,  0.,  0.])\n",
    "fake_image = torch.rand(batchSize,3,50,50).to(device) #torch.Size([3, 200, 200])\n",
    "for epoch in range(5):\n",
    "    #cuda-cache leeren\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    outputs = []\n",
    "    for true_image in trueloader:\n",
    "       \n",
    "        #1.Erstellung einer Random-Noise\n",
    "        #fake_image = torch.rand(batchSize,3,50,50).to(device) #torch.Size([3, 200, 200])\n",
    "              \n",
    "        \n",
    "        ###### Train Generator\n",
    "        #Gradienten des Generators zurücksetzen\n",
    "        gen_optimizer.zero_grad()    \n",
    "        \n",
    "        #G.1 Daten mit der Random-Noise generieren\n",
    "        fake_generated = generator(fake_image)#.to(device)\n",
    "        #G.2 Fehler mit der fake_generated und den Target 11111... berechnen\n",
    "        loss_gen_fake = criterion(fake_generated,torch.ones(batchSize, 3, 197, 197, dtype=torch.float).to(device))     \n",
    "        #G.3 Backpropagation für die fake_generated des Generators        \n",
    "        loss_gen_fake.backward()\n",
    "        #G.4 Gewichte des Generators mit dem Gradienten aktualisieren\n",
    "        gen_optimizer.step()    \n",
    "        #G.5 Generated Image in outputs speichern\n",
    "            \n",
    "            \n",
    "        ####### Train Discriminator\n",
    "        #Gradienten des Discriminators zurücksetzen\n",
    "        discr_optimizer.zero_grad()\n",
    "    \n",
    "        #D.1 Train Discriminator mit generierten Fake-Images\n",
    "        fake_prediction = discriminator(fake_generated)\n",
    "        #D.2 Fehler mit der fake_prediction und den Target 11111... berechnen\n",
    "        loss_discr_fake = criterion(fake_prediction.detach(), torch.zeros(batchSize,32, 25, 25, dtype=torch.float).to(device)) \n",
    "            #D.3 Backpropagation für die Fake-Prediction des Discriminators\n",
    "            #loss_discr_fake.backward()\n",
    "        #D.4 Train Discriminator mit True-Images\n",
    "        true_prediction = discriminator(true_image.to(device))\n",
    "        #D.5 Fehler mit der true_prediction und den Target 11111... berechnen\n",
    "        loss_discr_true = criterion(true_prediction, torch.ones(batchSize,32, 25, 25, dtype=torch.float).to(device))\n",
    "        #D.6 Backpropagation für die True-Prediction des Discriminators\n",
    "        loss_discr_true.backward()\n",
    "\n",
    "        #D.7 Gewichte des Discriminators mit dem Gradienten aktualisieren\n",
    "        discr_optimizer.step()\n",
    "        \n",
    "        outputs.append((epoch, true_image, fake_generated))             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d80b9-339e-4929-a275-60b87a645c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(outputs)):\n",
    "    plt.figure(figsize=(9,2))\n",
    "    timage = outputs[k*3][1].cpu().detach().numpy()\n",
    "    fiamge = outputs[k*3][2].cpu().detach().numpy()\n",
    "    for i, item in enumerate(timage):\n",
    "        if i >= 9: break\n",
    "        plt.subplot(2, 9, i+1)\n",
    "        #item = item.reshape(-1, 28, 28)\n",
    "        plt.imshow(item[0])\n",
    "            \n",
    "    for i, item in enumerate(fiamge):\n",
    "        if i >= 9:break\n",
    "        plt.subplot(2,9, 9+i+1)\n",
    "        #item = item.reshape(-1,28,28)\n",
    "        plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2dae5-58b7-4ca0-be7e-c1b6324aa3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d634e-46a2-4e46-a51b-fc004b5e0865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d7f1aed-5532-4e38-8854-c8565b5b87ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "Fake-Images generieren\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726b578-39bc-4df8-aa1f-76c32f87a276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_image():\n",
    "    rndm_image = np.random.rand(200, 200) #Erstellung eines random arrays mit 200x200 \n",
    "    rndm_image = Image.fromarray(rndm_image).convert('RGB')  #Array in ein RGB-Array konvertieren\n",
    "    rndm_image_tensor = transforms(rndm_image) #Array in ein Tensor umwandeln\n",
    "    return rndm_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57261e-2837-4d1c-bac3-0dd356880cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake_images = []\n",
    "for i in range(338):\n",
    "    #rndm_image = torch.rand(200,200)[None, :, :]\n",
    "    rndm_image = np.random.rand(200, 200) #Erstellung eines random arrays mit 200x200 \n",
    "    rndm_image = Image.fromarray(rndm_image).convert('RGB')  #Array in ein RGB-Array konvertieren\n",
    "    rndm_image_tensor = transforms(rndm_image) #Array in ein Tensor umwandeln\n",
    "    fake_images.append(rndm_image_tensor)  #Random Tensor in eine Liste mit Fake Images überführen \n",
    "fake_images[0].shape\n",
    "    \n",
    "#DataLoader für fake Bilder\n",
    "fakeloader = torch.utils.data.DataLoader(fake_images, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "f_dataiter = iter(fakeloader)\n",
    "f_images = f_dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfe449-166b-4c5f-bb9d-831c9be62d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch_size definieren, um Variable wieder zu verwenden und spätere Fehler zu vermeiden\n",
    "batchSize = 4\n",
    "\n",
    "transforms = transforms.Compose([transforms.Resize(50),\n",
    "                                 transforms.CenterCrop(50),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 #transforms.Normalize((0.5,), (0.5,))\n",
    "                                ])\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder('C:/Users/meldr/PythonProjects/Aufgabe04/TeilmengeBilder/', transform=transforms)\n",
    "\n",
    "#DataLoader für echte Bilder\n",
    "trueloader = torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=True, num_workers=1) #pin_memory=True -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7064b0b8-395a-4481-a63d-3c3ebed1c7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Wir müssen die Range der Daten analysieren, um zu wissen, welche Aktivierungsfunktion wir verwenden. Die Range kann mittels .Normalize verändert werden\n",
    "t_dataiter = iter(trueloader)\n",
    "t_images = t_dataiter.next()\n",
    "print(torch.min(t_images), torch.max(t_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09749281-e711-492c-87cd-04befc9b3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs = []\n",
    "\n",
    "#Definition der Target-Werte, um den Loss zu berechnen\n",
    "true_target = torch.ones(batchSize,3, 50, 50).to(device)\n",
    "#Die echten Inputs sollen auf den Wert 1 trainiert werden\n",
    "#torch.ones: Gibt einen Tensor zurück, der mit dem Skalarwert 1 gefüllt ist  \n",
    "#und dessen Form durch das variable Argument size definiert ist. \n",
    "#Bspw. torch.ones(5) -> tensor([ 1.,  1.,  1.,  1.,  1.])\n",
    "\n",
    "false_target = torch.zeros(batchSize,3,50,50).to(device)\n",
    "#Die falschen Inputs sollen auf en Wert 0 trainiert werden\n",
    "#torch.zeros: Gibt einen Tensor zurück, der mit dem Skalarwert 0 gefüllt ist  \n",
    "#und dessen Form durch das variable Argument size definiert ist. \n",
    "#Bspw. torch.zeros(5) -> tensor([ 0.,  0.,  0.,  0.,  0.])\n",
    "\n",
    "for epoch in range(10):\n",
    "    for true_img in trueloader:\n",
    "\n",
    "        ###### Train Generator\n",
    "        #Gradienten des Generators zurücksetzen\n",
    "        gen_optimizer.zero_grad()    \n",
    "        \n",
    "        #1.Erstellung einer Random-Noise\n",
    "        fimg = torch.rand(batchSize,3,1,1).to(device) #torch.Size([3, 200, 200])\n",
    "        \n",
    "        #2.Generator mittels Random-Noise durchführen \n",
    "        fake_gen_out = generator(fimg).to(device)\n",
    "        print('Generator mit Random-Noise abgeschlossen')\n",
    "        \n",
    "        #3.Discriminator mit dem Fake-Output des Generators füttern\n",
    "        fake_discr_out = discriminator(fake_gen_out)\n",
    "        print('Discriminator mit generierten Fake-Images abgeschlossen')\n",
    "    \n",
    "        #4.Loss für den Fake-Output des Discriminators berechnen\n",
    "        loss_discr_fake = criterion(fake_discr_out, true_target)\n",
    "        print('Loss für den Discriminator mit generierten Fake-Output  berechnet')\n",
    "        \n",
    "        #5.Backpropagation über den loss des Fake-Outputs des Discriminator\n",
    "        loss_discr_fake.backward()\n",
    "        \n",
    "        #7. Gewichte des Generators mit dem Gradienten aktualisieren\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        ####### Train Discriminator\n",
    "        #Gradienten des Discriminators zurücksetzen\n",
    "        discr_optimizer.zero_grad()\n",
    "        \n",
    "        #1.Discriminator mit den echten Images füttern\n",
    "        true_discr_out = discriminator(true_img).to(device)\n",
    "        print('Discriminator mit Echten-Images abgeschlossen')\n",
    "        print(true_discr_out.shape)\n",
    "        #print(torch.argmax(true_target, dim=1).shape)\n",
    "        #2.Loss für den True-Discriminators und den True-Labels bilden\n",
    "        loss_discr_real = criterion(true_discr_out, true_target)\n",
    "        print('Loss für den Discriminator mit echten Images berechnet')\n",
    "\n",
    "        \n",
    "        #3. Discrimininator mit den Fake-Output des Generators füttern\n",
    "        gen_discr_out = discriminator(fake_discr_out.detach()).to(device)\n",
    "                #.detach() Erzeugt einen Tensor, der sich den Speicher mit einem \n",
    "                #Tensor teilt, der keinen Gradient benötigt. Er trennt die Ausgabe\n",
    "                #vom Berechnungsgraphen ab. Es wird also kein Gradient entlang dieser\n",
    "                #Variablen zurückverfolgt.\n",
    "       # print('Discriminator mit Echten-Images abgeschlossen')\n",
    "\n",
    "        \n",
    "        #4. Loss für den Fake-Output des Discriminators berechnen\n",
    "        gen_discr_loss = criterion(gen_discr_out, false_target)\n",
    "                \n",
    "                \n",
    "        #5. Finalen loss mitteln \n",
    "        discr_loss = (loss_discr_real + gen_discr_loss)  / 2\n",
    "        \n",
    "        #6. Backpropagation\n",
    "        discr_loss.backward()\n",
    "        \n",
    "        #7. Gewichte des Discriminators mit dem Gradienten aktualisieren\n",
    "        discr_optimizer.step()\n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59d166-d708-41af-9bf2-4ce33bddabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__() #Superkonstruktor für das NN\n",
    "        \n",
    "        #batch_size = 4, size = 2500 (50x50 Pixel)\n",
    "        self.conv1 = nn.Conv2d(3, 250, 5, stride=1, padding=2), # 250 = (1+250-5+2*2)/1\n",
    "        self.conv1ReL = nn.ReLU(), #Relu-Aktivierungsfunktion\n",
    "        self.conv2 = nn.Conv2d(250, 125, 5, stride=2, padding=2), #1250 = (1+250-5+2*2)/2\n",
    "        self.conv2ReL = nn.ReLU(), #Relu-Aktivierungsfunktion\n",
    "        self.conv2 = nn.Conv2d(125, 31, 6, stride=4, padding=2), # 31 = (1+125-6+2*2)/4\n",
    "       \n",
    "        self.fc1 = nn.Linear(16*5*5,200)\n",
    "        self.fc2 = nn.Linear(200,150)\n",
    "        self.fc3 = nn.Linear(150,10)\n",
    "   \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        print(f'Input Discriminator:{x.shape}')\n",
    "        x = self.conv1ReL(self.conv1(x))\n",
    "        x = self.conv2ReL(self.conv2(x))\n",
    "        x = x.view(-1,77500)\n",
    "        print(f'Output Discriminator:{x.shape}')\n",
    "        return x\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb51404d2d7ecbcc3d85c660483a2b3b505e2cbbc46315fe42c850b2013b97ff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
